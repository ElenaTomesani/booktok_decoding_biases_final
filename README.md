# Decoding Biases in Artificial Intelligence: Exploring Racial Bias on TikTok through a subcommunity: #BookToK
#### Joshua Bernstein, Maria Chiara Liviano D’Arcangelo, Frida Hellen, Benjamin Saldich, Elena Tomesani  – Winter 2024


## Table of Contents

[1. Introduction](#intro)

[2. Literature Review](#litrev)

[3. Methodology](#methods)

[4. Result and Analysis ](#results)

[5. Discussion](#discussions)

[Conclusion](#conclusions)

[References](#bibliography)



<a name="intro"></a>
## Introduction
<p>
write here
</p>


<a name="litrev"></a>
## Literature Review
<p>
The availability of literature that explores racial biases in TikTok subcommunities and their economic influence is limited and merits further study. Studying the algorithmic biases embedded within TikTok and the #BookTok subcommunity can contribute to literature dedicated to explaining how and why authors and creators who identify as Biracial, Indigenous or a Person of Colour (BIPOC) are being marginalized in sub-communities. 

#BookTok A Disruptor of the Publishing Industry
The emergence of the #BookTok sub-community during the COVID-19 lockdowns throughout 2020 and 2021 has completely changed how authors market their books to reach new audiences (Barnett, 2023). What started as a small sub-community for people to connect during a period of loneliness and social isolation has become so popular that the #BookTok hashtag has now grown to have over six billion reposts (Ariyanayagam, 2023). News outlets like The New York Times, The Guardian and the BBC have reported the swaths of young people coming into bookstores to buy titles of old but seemingly up-and-coming authors in adult fiction (science-fiction, romance and fantasy) that viewers saw on #BookTok (Harris, 2022). The #BookTok subcommunity has completely disrupted the entire publishing industry by putting the readers in charge of the market rather than the publishers and the authors. It has allowed certain authors to profit greatly from this new marketing tool. In a report on the United States (U.S.) book market, insights company Circana found that despite the three percent drop in publishing and sales volume in the U.S., sales of books in the fiction category increased by one percent. This indicates that although there has been a drop in sales, #BookTok might have impacted the sales in this category (Chojnacki, 2024). Despite this newfound success, there is ambiguity about which authors benefit most. Colleen Hoover, a white, middle-aged female American author who has been publishing books since 2012, became famous in 2020 and has since sold more copies of her book than the bible (Alter, 2022).  Between 2022 and 2024, most weeks, Hoover had one of her books listed under the Combined Print & E-Book Fiction Category on The New York Times Bestseller List (The New York Times, n.d.). As a member of this group Hoover is among one of the authors who has been able to profit from #BookTok immensely. However, there are questions about whether authors of colour and of different ethnicities have had the same success.  
In 2022, as #BookTok was changing the publishing industry, The Cut Magazine, published an article about the racial bias on #BookTok (McCall, 2022). It explained that most of the authors like Colleen Hoover, who have experienced success from #BookTok, are white (McCall, 2022). The article details how bookstores are seeing readers pick up books with a lack of racial or ethnic diversity in the characters and reports that the “algorithm” is responsible for this discrepancy. Independent and new authors also found that as #BookTok was becoming popular, there was a lot of content from BIPOC authors, which has since been de-popularized (McCall, 2022). “It seems like the algorithm did drown out the POC authors and the readers as well.” (McCall, 2022). The article also details how black creators on the platform do not get the same visibility unless they “stitch” a video of a white creator (McCall, 2022). The popular media and news outlets referenced above report evidence-based conclusions that are by no means empirical or academically rooted. A preliminary analysis of the evidence embedded within this discussion indicates that the recommendation system TikTok is using for the platform perhaps has contributed to a racial bias and influenced the publishing market through #BookTok. 

The Sensitivity of the TikTok Algorithm and Folk Theories on #BookTok
The idea of online book reviews is not a new concept. Platforms such as Goodreads and Amazon have allowed users to upload and share reviews long before #BookTok became a popular medium for this exchange to take place. However, other platforms like TikTok, such as Instagram or Facebook, do not seem to have the same culture that #BookTok has fostered on TikTok. In their work, Taylor and Choi (2022) compare the perceived algorithm responsiveness (PAR) and perceived algorithm insensitivity (PAI) on Facebook, TikTok, Instagram and Twitter. They also hypothesize that PAR predicts content satisfaction levels. They found that TikTok was the most sensitive and responsive to users. This result helps to explain why the perception of an algorithm on TikTok allows users to control it more, giving them the power to partially understand their choice of videos (Taylor & Choi, 2022). In addition to perceptions of sensitivity and responsiveness, there has been some discussion in the literature about why #BookTok might have emerged on TikTok instead of other algorithms. Bhandari and Bimo’s (2022) study, through a qualitative analysis of TikTok users, offers three main factors: the awareness of an algorithm, the volume of content and lack of context, and the creation of their own experience on TikTok (Bhandari & Bimo, 2022). Of these three factors, the latter two are most interesting. These findings question the ways in which TikTok predicts exactly what users seek and how much users create their own experiences. This study may help to explain the encoded biases in the TikTok algorithm that present users with an opportunity to connect with white authors versus authors who identify as BIPOC. 

The Emergence of Racial Biases on TikTok or Statistics? 
The first reports of racial biases on TikTok appeared in 2022 when National Public Radio (NPR) in the U.S. published an article about TikTok’s shadow banning of non-white creators (Kung, 2022). NPR reported that black creators who used tags like #BlackLivesMatter on their videos were censored, and some videos received zero views (Kung, 2022). After NPR’s report, TikTok acknowledged and apologized for what it termed a “glitch,” explaining this technical issue was also impacting other hashtags, including #cat and #dog (Shead, 2020). The reports in this article were empirically investigated by academics when Harris et al. (2023) conducted semi-structured interviews with twelve black creators. The researchers found that black creators had the largest problems with TikTok moderation and suppression, and authors who conducted interviews “that common perceptions held by Black creators of the algorithm are that it lacks transparency and filters our marginalized identities from being shown to a wide audience”(Harris et al., 2023). Two examples are worth sharing. First, some interviewees in the study indicated that if they used African American Vernacular English (AAVE), black creators might get sanctioned on TikTok for what it determines to be hate speech (Harris et al., 2023). This type of mislabelling and censorship acts as a barrier for BIPOC creators to reach audiences. Second, interviewees also indicated the presence of shadow banning, where videos were not formally reviewed by TikTok content moderators but placed in a grey area (Harris et al., 2023). Barriers like these have also led to greater difficulty with monetization, with creators indicating that upon comparing themselves to white viewers with similar account metrics, these individuals made more money per month.

“I can see the white creators who have less viewers than me…saying “here’s how I made 10,000 [dollars per month]... and they… will only have their account for a year…But me as a Black creator I’ve been here for three years and I’m not making nowhere near 10K…” (Harris et al., 2023)

In addition to the meaningful discussion on black creators, the discourse on viewer perception provides insights into how social media users define meaning. According to Melany Amarikwa (2023), who builds on Anita Allen (2022) and her concept of the “Black Opticon,” this concept theorizes how black people are surveilled and discriminated against on social media through what Allen terms exclusion of black people in “Discriminatory exclusion.” Defined as “excluding people of colour from beneficial opportunities based on race” (Amarikwa, 2023), discriminatory exclusion occurs when individuals or a platform aims to ensure people of colour (POCs) do not receive the same treatment or financial opportunities on the platform as their white and non-POC counterparts excluding people of colour from beneficial opportunities based on race. The literature available about the impact of TikTok on its diverse creator communities indicates the presence of discrimination against BIPOC creators and the experience of the viewers with whom they interact through their content. Although limited and specific in scope, this literature highlights the presence of an issue that must be addressed and requires further investigation. While this literature focused on TikTok in its entirety, the absence of focus on sub-communities within each of these studies supports the case for a more focused analysis. 
To fill the gap in the literature, the research question behind our study asks: Does the TikTok algorithm display a preference for white authors and white influencers in the #BookTok subcommunity? 
</p>

<a name="methods"></a>
## Methodology
<p>
Though #BookTok is used across many languages and countries, our group’s interest in potential racial biases present in TikTok’s search results necessitated an in depth focus on one geographic location. Given the existing literature on racial disparities in the United States, and the emerging reports on BookTok’s racial bias in the American context, we aimed to collect primarily U.S. TikTok posts. To do so, a VPN was employed throughout the entire process of account creation and data collection, with an arbitrary location within the United States set to Phoenix, Arizona. Using the active VPN, a new TikTok account was created with a new email to mitigate the potential for data traceability. A selfie is required to authenticate new TikTok accounts. This selfie was taken by a member of our team (a white man). Aside from a few preliminary searches on the account, no other actions were performed on the account until our data collection commenced. 

Data collection was performed using the traffic monitoring Firefox extension, Zeeschuimer, paired with the auto-scrolling extension FoxScroller. Developed by the Digital Methods Initiative at the University of Amsterdam, Zeeschuimer allows users to collect data while they browse various social media websites, including Twitter, Instagram, LinkedIn, and TikTok. Using Firefox Nightly in conjunction with the Arizona-based VPN, the new TikTok account was accessed. At this step, the Zeeschuimer extension was activated, and a search query was performed for #BookTok. Data collection was performed until no more results were offered. In total, 381 posts were collected, a small but meaningful sample when considering the team’s manual coding framework. 

Using 4CAT, Zeeschuimer’s companion data processing tool, data was converted from a .NDJSON format to a .csv format. These data contained information on the post time, author, text body, as well as information on the account’s popularity and post-level engagement and viewership data. Surprisingly, these posts ranged from August 2021 to the time of data collection in April 2024, indicating that post-recency is but one of many factors present in TikTok’s search results algorithm. After collecting the data, a manual coding process was enacted, with coding performed across 7 categories (category-specific options provided in parentheticals):

Whether the post was a review (non-reviews included viral book-themed trends that also employed #BookTook. Given their lack of relevancy, these data were excluded from further analysis)
The sentiment of the review (Positive, Negative, or mixed)
The perceived gender of the influencer (Male, Female, unable to tell)
The perceived race of the influencer (White, Black, unable to tell) 
The name of the author of the first book reviewed in the post
The name of the author of the second book reviewed in the post
The name of the author of the third book reviewed in the post

Additionally, each author identified in the views was manually researched and labeled according to perceived race (White, Black, non-Black POC, mixed-race, or can’t tell) and gender (female or male). Importantly, race and gender-based identifications performed by our team were done using visual identification strategies, introducing the notable limitation that our results may be biased by incorrect labeling. This is particularly true when considering white-passing POC, mixed-race individuals, and/or individuals whose physical appearance do not conform to typical gender or racial divisions. This risk was partially mitigated by the inclusion of the “unable to tell" category, which was utilized under more ambiguous situations, but nonetheless presents notable limitations to our analysis. Once collected, data was cleaned, removing certain posts in different languages whose content could not be coded (n=3), as well as posts that were not viewable to those without a TikTok account (n=3).

Coders also recorded the names of the first three authors referenced in a given BookTok review. These authors were researched online, and their perceived races were recorded using the same visual identification techniques (or in some cases, utilizing online reporting around the given author). Coders also recorded the perceived or reported gender of the author. 

To develop a comparison group, data from bestselling books on the New York Times Bestseller list were gathered using the New York Times book API. New York Times bestseller data was collected during two periods: in 2019, prior to the popularity of BookTok, and in 2024, when our BookTok data was collected. 

The resulting data contained three datasets: 1) our corpus of TikTok posts with our complete manual coding, 2) our author dataset, containing the authors mentioned in the posts alongside their perceived races and genders, and 3) our New York Times bestseller data. 

Various cross-sections of the data were analyzed, including the race and gender breakdowns of both the influencers recorded in our corpus, the equivalent breakdown of authors referenced by these influencers, and interactions between the race and gender of influencers and the books that they recommended.
</p>

**<a name="results"></a>
## Results and Analysis
<p>

<img width="762" alt="1" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/47e509c5-ef36-4517-a40f-03f838d70415">
Colleen Hoover and Ana Huang seem to be the most frequently mentioned authors in the booktok community with 36 and 28 mentions respectively as the first three authors mentioned in a tiktok.

<img width="377" alt="2" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/02e0f2b6-1b35-41f0-b33e-f623b7534783">
We can see from the graph that the majority of booktok-related tiktoks are indeed reviews, even though a considerable amount (around a quarter of the total) are not reviews.

<img width="414" alt="3" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/0a5ac3d7-5a53-4d79-a4dd-d325da79f908">
Almost 9 out of 10 reviews are positive in respect to the authors they showcase. Around 7% of the reviews fall under the "Yes and no" category, which indicates tiktoks that often displayed "most recently read books" kind of videos, including liked and disliked books.

What is the distribution over time of our tiktok sample?
<img width="882" alt="4" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/b904f5d5-0077-4c36-9596-512cd3d95b3f">
From the collected sample, it seems like the number of booktok-related tiktoks has been increasing considerably since mid 2022 and has received a hit in the most recent months of 2024. Nevertheless, it is hard to generalise this finding to a broder trend regarding booktok in general.

What are the recurrent words that appear below these tiktoks? We can have a look at the frequency distribution of words in the captions of the booktok commmunity.
<img width="708" alt="5" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/f6a9ba1e-6663-45a4-a3a5-709780048d55">
It seems like versions of the word "booktok" are the most frequent components of tiktoks captions. The captions seem to be mainly made up of disaggregated hashtags, rather than coherent text.

What about the languages of these tiktoks?
<img width="757" alt="6" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/4ce1c8b0-504a-468d-a64d-269747e52d6a">
It is evident that the vast majority of booktoks analysed are in English.

Let's dive into the gender and race dimension of booktok!
<img width="480" alt="7" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/c0434dbc-3ca7-4fd1-b4c9-048e88f46fb5">

<img width="362" alt="8" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/32c76d48-e354-4b39-9688-04a72e8961ac">
Heavily female-dominated community!

<img width="362" alt="9" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/4d4d2de8-6b4f-4d85-b81a-7c3892aebdd1">
From the graphs above it is clear how much BookTok is polarised in terms of gender representation both for influencers and authors. Female influencers take up an overwhelming 80.1% of the entirety of tiktoks taken in consideration. A similar percentage is reflected in the authors' category where "Non-male" authors amount at 80.2%. It is arguably more intersting to look at the male representation is both groups. Whilst for influencers they only reach 8.7%, male authors arrive at almost 20% of authors recommended on the platform.

We can perform a similar analysis to investigate racial bias on BookTok, the focus of our research.
<img width="376" alt="10" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/e9f792e1-f7c3-4501-b3f6-1c152b6a7d91">
The "Can't Tell" section might be due to either the impossibility to differentiate an influencer's race or to the impossibility to see the influencer (e.g. videos without images of the influencer).

<img width="390" alt="11" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/1a9e8abe-7710-4491-b40c-22277a2ae4bd">
The white component seems higher for authors than influencers (82.2% vs 71.3%). Nevertheless, the non-white component is also higher for authors than influencers (16.4% vs 11.1%). This is due to a much smaller share of "Can't Tell" values for authors than influencers.

Looking more closely at the racial composition of male and female influencers:
<img width="338" alt="12" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/19873e8b-a8c2-4854-b94f-34df7c8f3b04">
<img width="338" alt="13" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/f88bdced-e942-471f-97a9-30ac1fedafac">
Pretty consistent racial composition across male and female influencers. Value count of "Can't Tell" influencing non-white share differences.

Looking more closely at the racial composition of male and female authors:
<img width="359" alt="14" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/06c671b9-fd80-4f7c-ae86-40371b5fe77d">
<img width="348" alt="15" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/97269ba3-fe71-43f5-adec-3e69402dd898">
Again, consistent results for authors as well. Very much white dominated community on both ends.

We are going to see if race plays a factor in determining the attention and success that an influencer receives in the BookTok community. We are going to use the mean values of number of followers, likes and number of videos published by influencers categorising them by race.
<img width="469" alt="16" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/e4990e6c-3f28-4f58-b8af-f8a5e7443a02">
<img width="442" alt="17" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/fa686c79-2eaa-404f-99a3-7a5ca760c42a">
<img width="426" alt="18" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/f49cdce5-42bd-400b-ae23-87889a44805d">
The results obtained from the analysis of profile statistics by race indicate that non-white authors tend to have on average significantly more followers and more likes. In terms of videos produced, the difference between white and non-white authors is instead not particularly relevant.

We are intersted in understanding if the results we got are driven by huge outliers or if they represent a general trend. We do it by utilizing boxplots.
<img width="465" alt="19" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/10195809-b1f6-4331-8e80-4cfc0da8ab25">
<img width="468" alt="20" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/51f49a79-4128-4033-a3ec-4c4d6194c487">

Lets do the same for likes and videos!
<img width="468" alt="21" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/1bf289b4-6080-426c-a428-4b0d167d685e">
<img width="468" alt="22" src="https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/50c70c4c-8647-4196-832c-51591179e907">
<img width="
![23](https://github.com/bensaldich/booktok_decoding_biases_final/assets/166377571/5fddf666-841f-4ab4-8b99-4a222a5f0c74)



</p>**



<a name="discussions"></a>
## Discussion
<p>
write here 
</p>


<a name="conclusions"></a>
## Conclusion
<p>
Write here
</p>

<a name="bibliography"></a>
## References
<p>
write here
</p>

